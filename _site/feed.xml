<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Laksh Gupta</title>
    <description>A Blog for Some Stuff</description>
    <link>http://lakshgupta.github.io/</link>
    <atom:link href="http://lakshgupta.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>2015-08-18 05:47:10 +0000</pubDate>
    <lastBuildDate>2015-08-18 05:47:10 +0000</lastBuildDate>
    <generator>Jekyll v</generator>
    
      <item>
        <title>Vector Representation of Words - 1</title>
        <description>&lt;div tabindex=&quot;-1&quot; id=&quot;notebook&quot; class=&quot;border-box-sizing&quot;&gt;
    &lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let us see how we can process the textual information to create a vector representation, also known as word embeddings or word vectors, which can be used as an input to a neural network.&lt;/p&gt;
&lt;h2 class=&quot;section-heading&quot;&gt;One-Hot Vector&lt;/h2&gt;&lt;p&gt;This is the most simplest one where for each word we create a vector of length equal to the size of the vocabulary, $R^{\left\|V\right\|}$. We fill the vector with $1$ at the index of the word, rest all $0s$.&lt;/p&gt;
$$W^{apple} = 
\begin{bmatrix}
  1 \\ 
  \vdots \\
  \vdots \\
  \vdots \\
  0 \\
\end{bmatrix}
W^{banana} = 
\begin{bmatrix}
  0 \\ 
  1 \\
  \vdots \\
  \vdots \\
  0 \\
\end{bmatrix}
W^{king} = 
\begin{bmatrix}
  0 \\ 
  \vdots \\
  1 \\
  \vdots \\
  0 \\
\end{bmatrix}
W^{queen} = 
\begin{bmatrix}
  0 \\ 
  \vdots \\
  \vdots \\
  1 \\
  0 \\
\end{bmatrix}$$&lt;p&gt;All these vectors are independent to each other. Hence this representation doesn't encodes any relationship between words:&lt;/p&gt;
$$(W^{apple})^TW^{banana}=(W^{king})^TW^{queen}=0$$&lt;p&gt;Also, each vector would be very sparse. Hence this approach requires large space to encode all our words in the vector form.&lt;/p&gt;
&lt;blockquote&gt;
You shall know a word by the company it keeps (Firth, J. R. 1957:11)
&lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;https://en.wikipedia.org/wiki/John_Rupert_Firth&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;&lt;h2 class=&quot;section-heading&quot;&gt;Word-Document Matrix&lt;/h2&gt;&lt;p&gt;In this approach, we create a matrix where a column represents a document and a row represents the frequency of a word in the document. This matrix scales with the number of documents ($D$). The matrix size would be $R^{\left\|D*V\right\|}$ where $V$ is the size of the vocabulary.&lt;/p&gt;
&lt;h2 class=&quot;section-heading&quot;&gt;Word-Word Matrix&lt;/h2&gt;&lt;p&gt;In this case, we build a co-occurence matrix where both columns and rows represent words from the vocabulary. The benefit of building this matrix is that the co-occurence value of the words which are highly likely to come together in a sentence will always be high as compared to the words which rarely come together. Hence we should be fine once we have a descent sized dataset or say documents. Also, the size of the matrix dependent now on the size of the vocabulary, $R^{\left\|V*V\right\|}$.&lt;/p&gt;
&lt;p&gt;The beauty of the last two approaches is that we can apply &lt;a href=&quot;https://en.wikipedia.org/wiki/Singular_value_decomposition&quot;&gt;Singular-Value-Decomposition&lt;/a&gt; (SVD) on the matrix and further reduce the dimentionality. Let us see an example on the Word-Word matrix.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Consider our data to have the following 3 sentence:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I enjoy driving.&lt;/li&gt;
&lt;li&gt;I like banana.&lt;/li&gt;
&lt;li&gt;I like reading.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The co-occurence matrix will look like:&lt;/p&gt;
$$X = 
\begin{array}{c|lcr}
words &amp;amp; \text{I} &amp;amp; \text{enjoy} &amp;amp; \text{driving} &amp;amp; \text{like} &amp;amp; \text{banana} &amp;amp; \text{reading} &amp;amp;\text{.}\\
\hline
\text{I} &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
\text{enjoy} &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
\text{driving} &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
\text{like} &amp;amp; 2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 \\
\text{banana} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
\text{reading} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
\text{.} &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 \\
\end{array}
$$
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[2]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;I&amp;quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;enjoy&amp;quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;driving&amp;quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;like&amp;quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;banana&amp;quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;reading&amp;quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
       &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
       &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In &lt;a href=&quot;http://julia.readthedocs.org/en/latest/stdlib/linalg/&quot;&gt;Julia&lt;/a&gt;, applying SVD on our matrix $X$ will give us $U$, $S$ and $V$ where:&lt;/p&gt;
&lt;center&gt;$$A == U*diagm(S)*V^T$$&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[3]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[4]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[4]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;7x7 Array{Float64,2}:
  0.723607      0.0          -5.55112e-17  …   0.276393      4.24034e-17
  2.77556e-16  -0.356822     -1.38778e-16     -3.747e-16    -5.54668e-32
  0.276393     -1.04083e-17   1.66533e-16      0.723607      1.73914e-18
 -2.22045e-16  -0.835549     -0.447214         1.94289e-16   2.46519e-32
  0.447214      7.08113e-18  -1.26097e-16     -0.447214      0.707107   
  0.447214      7.08113e-18  -1.26097e-16  …  -0.447214     -0.707107   
  0.0          -0.417775      0.894427        -8.32667e-17  -1.2326e-32 &lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[5]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[5]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;7-element Array{Float64,1}:
 2.80252    
 2.80252    
 1.41421    
 1.41421    
 1.07047    
 1.07047    
 1.34641e-17&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[6]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[6]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;7x7 Array{Float64,2}:
 -0.0          -0.723607     -0.632456     …  -0.0           0.0        
  0.356822     -1.11022e-16   2.22045e-16      0.934172     -4.996e-16  
  1.52656e-16  -0.276393      0.632456        -6.10623e-16   4.7621e-18 
  0.835549      1.9845e-17   -1.78328e-16     -0.319151      1.01714e-16
  0.0          -0.447214      0.316228        -1.11022e-16  -0.707107   
  0.0          -0.447214      0.316228     …   4.44089e-16   0.707107   
  0.417775      0.0           0.0             -0.159576      2.11234e-16&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;blockquote&gt;&lt;p&gt;&quot;A useful rule of thumb is to retain enough singular values to make up
90% of the energy in Σ. That is, the sum of the squares of the retained
singular values should be at least 90% of the sum of the squares of all the
singular values.&quot; - Jeffrey D. Ullman&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;S matrix is the $\sum$, hence the total energy here is:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[7]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;totEnergy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[7]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;22.0&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[8]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;energy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;energy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;totEnergy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;energy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;energy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;totEnergy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;energy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[8]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;7-element Array{Float64,1}:
 0.357005
 0.714009
 0.804918
 0.895827
 0.947914
 1.0     
 1.0     &lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[9]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PyPlot&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt&quot;&gt;&lt;/div&gt;
&lt;div class=&quot;output_subarea output_stream output_stderr output_text&quot;&gt;
&lt;pre&gt;INFO: Loading help data...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[10]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;energy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;energy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Dimensions&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;% Energy Retained&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;on&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt&quot;&gt;&lt;/div&gt;


&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Looking at the plot we can determine that keeping 4 dimensions are good enough for us rather than all 6. We can also print/plot the words based on the first two columns of $U$ corresponding to the two biggest singular values.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[11]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[11]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;7x4 Array{Int64,2}:
 0  1  0  2
 1  0  1  0
 0  1  0  0
 2  0  0  0
 0  0  0  1
 0  0  0  1
 0  0  1  0&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[12]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[13]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[13]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;7x4 Array{Float64,2}:
 -0.853553     -1.87443e-17  -1.09429e-16  -0.146447   
 -2.35514e-16  -0.541467     -0.51222       1.57009e-16
 -0.146447     -2.81165e-17  -1.64143e-16  -0.853553   
  1.96262e-16  -0.831251      0.444872     -3.92523e-17
 -0.353553      0.0           0.0           0.353553   
 -0.353553      0.0           0.0           0.353553   
  7.85046e-17  -0.125841     -0.734656     -7.85046e-17&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[14]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt&quot;&gt;&lt;/div&gt;


&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In the coming posts, I'll write about more interesting ways of generating word vectors.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 class=&quot;section-heading&quot;&gt; References: &lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://arxiv.org/abs/1003.1141&quot;&gt;From Frequency to Meaning: Vector Space Models of Semantics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://arxiv.org/abs/1301.3781&quot;&gt;Efficient Estimation of Word Representations in Vector Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.ling.ohio-state.edu/~kbaker/pubs/Singular_Value_Decomposition_Tutorial.pdf&quot;&gt;Singular Value Decomposition Tutorial PDF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://infolab.stanford.edu/~ullman/mmds/ch11.pdf&quot;&gt;Dimensionality Reduction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
</description>
        <pubDate>2015-07-12 12:00:00 +0000</pubDate>
        <link>http://lakshgupta.github.io/2015/07/12/VectorRepresentationofWords1/</link>
        <guid isPermaLink="true">http://lakshgupta.github.io/2015/07/12/VectorRepresentationofWords1/</guid>
        
        
      </item>
    
      <item>
        <title>Neural Network</title>
        <description>&lt;div tabindex=&quot;-1&quot; id=&quot;notebook&quot; class=&quot;border-box-sizing&quot;&gt;
    &lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 class=&quot;section-heading&quot;&gt;The Problem&lt;/h2&gt;

&lt;p&gt;Single neuron has limited computational power and hence we need a way to build a network of neurons to make a more complex model. In this post we will look into how to construct a neural network and try to solve the handwritten digit recognition problem. The goal is to decide which digit it represents when given a new image.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 class=&quot;section-heading&quot;&gt;Understanding the Data&lt;/h2&gt;

&lt;p&gt;We'll use the &lt;a href=&quot;http://yann.lecun.com/exdb/mnist/&quot;&gt;MNIST dataset&lt;/a&gt;. Luckily, &lt;a href=&quot;https://github.com/johnmyleswhite/MNIST.jl&quot;&gt;John Myles White&lt;/a&gt; has already created a package to import this dataset in Julia. The MNIST dataset provides a training set of 60,000 handwritten digits and a test set of 10,000 handwritten digits. Each of the image has a size of 28×28 pixels. &lt;img src=&quot;/img/nn/MNIST_digits.png&quot; alt=&quot;MNIST&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[1]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;#Pkg.update();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Pkg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;MNIST&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Pkg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;PyPlot&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Pkg.installed();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;For plotting, PyPlot is a good option. It provides a Julia interface to the Matplotlib plotting library from Python.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[2]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PyPlot&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt&quot;&gt;&lt;/div&gt;
&lt;div class=&quot;output_subarea output_stream output_stderr output_text&quot;&gt;
&lt;pre&gt;Qt: Untested Windows version 10.0 detected!
INFO: Loading help data...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[3]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# ===================&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# load training data&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ===================&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;traindata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#X:(784x60000), y:(60000x1)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# number of inputs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[3]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;60000&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 class=&quot;section-heading&quot;&gt;Training a model&lt;/h2&gt;

&lt;p&gt;We want to train a neural network with one input layer, one hidden layer and one output layer to recognize handwritten digits. Since the dataset contains 28×28 pixel images, our neural network will have $28*28=784$ input neurons, a variable number of hidden neurons and $10$ output neurons.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/img/nn/nn_basic.png&quot; alt=&quot;2-layer-neuralNetwork&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[4]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# ======================&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# network setup&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ======================&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inputLayerSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# number of input features: 784&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hiddenLayerSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# variable&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;outputLayerSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# number of output classes&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# since we are doing multiclass classification: more than one output neurons&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# representing each output as an array of size of the output layer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputLayerSize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#Y:(10,60000)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The appraoch to train a neural network is similar to what we have discussed in the &lt;a href=&quot;http://lakshgupta.github.io/2015/05/21/ArtificialNeuron/&quot;&gt;neuron post&lt;/a&gt;.  But since now we have a network of neurons, the way we follow the steps is a bit different. We'll use the &lt;a href=&quot;http://www.cs.toronto.edu/~hinton/absps/naturebp.pdf&quot;&gt;backpropagation algorithm&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Backpropagation works by approximating the non-linear relationship between the input and the output by adjusting the weight values internally. 
The operations of the Backpropagation neural networks can be divided into two steps: feedforward and Backpropagation. In the feedforward step, an input pattern is applied to the input layer and its effect propagates, layer by layer, through the network until an output is produced. The network's actual output value is then compared to the expected output, and an error signal is computed for each of the output nodes. Since all the hidden nodes have, to some degree, contributed to the errors evident in the output layer, the output error signals are transmitted backwards from the output layer to each node in the hidden layer that immediately contributed to the output layer. This process is then repeated, layer by layer, until each node in the network has received an error signal that describes its relative contribution to the overall error.
Once the error signal for each node has been determined, the errors are then used by the nodes to update the values for each connection weights until the network converges to a state that allows all the training patterns to be encoded.&lt;/p&gt;
&lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;http://www.cse.unsw.edu.au/~cs9417ml/MLP2/BackPropagation.html&quot;&gt;www.cse.unsw.edu.au&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We'll discuss more about the backpropagation algorithm later but first let's collect the simple tools which are required for training a neural network.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 class=&quot;section-heading&quot;&gt;Activation Function: $g$&lt;/h4&gt;

&lt;p&gt;The activation function of artificial neurons have to be differentiable and their derivative has to be non-zero so that the gradient descent learning algorithm can be applied. Considering &lt;a href=&quot;http://lakshgupta.github.io/2015/05/27/LinearRegression/&quot;&gt;linear regression&lt;/a&gt;, using a linear activation function does not give us much advantage here. Linear function applied to a linear function is itself a linear function, and hence both the functions can be replaced by a single linear function. Moreover real world problems are generally more complex. A linear activation function may not be a good fit for the dataset we have. Therefore if the data we wish to model is non-linear then we need to account for that in our model. Sigmoid activation function is one of the reasonably good non-linear activation functions which we could use in our neural network.&lt;/p&gt;
$$sigmoid(z) = 1/(1 + e^{-z})$$&lt;p&gt;&lt;img src=&quot;/img/nn/sigmoidGraph.png&quot; alt=&quot;sigmoid&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[5]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# ==============================================&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# activation function: computes the sigmoid of z &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# z is the weighted sum of inputs&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ==============================================&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;./&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# computes the gradient of the sigmoid function evaluated at z&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; sigmoidGradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[5]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;sigmoidGradient (generic function with 1 method)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 class=&quot;section-heading&quot;&gt;Cost Function: $J$&lt;/h4&gt;

&lt;p&gt;The “squared error” cost function used for linear regression is not suitable for neural networks, because the non-linear nature of activation function is said to produce a non-convex plot of the cost function, i.e. with many local minima. For further explanation refer to this &lt;a href=&quot;https://class.coursera.org/ml-005/forum/thread?thread_id=2773&quot;&gt;thread&lt;/a&gt;. Take a look at this &lt;a href=&quot;https://www-i6.informatik.rwth-aachen.de/publications/download/861/GolikPavelDoetschPatrickNeyHermann--Cross-Entropyvs.SquaredErrorTrainingaTheoreticalExperimentalComparison--2013.pdf&quot;&gt;paper&lt;/a&gt; to have a comparison between cross entropy cost function and squared error cost function. So considering:&lt;/p&gt;
$$J(\theta) = \frac{1}{m}(\sum_{i=1}^{m}cost(h_{\theta}(x^{(i)}),y^{(i)}))$$&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$h_{\theta}(x^{(i)})$ is the predicted value (hypothesis)&lt;/li&gt;
&lt;li&gt;$y^{(i)}$ is the actual value (truth), and
$$\begin{eqnarray}
cost(h_{\theta}(x^{(i)}),y^{(i)})&amp;amp;=&amp;amp;\left\{
\begin{array}{l l}      
  -\log(h_{\theta}(x^{(i)}))   &amp;amp;   \mathrm{if} \: y=1 \\
  -\log(1-h_{\theta}(x^{(i)})) &amp;amp;  \mathrm{if}  \: y=0
\end{array}\right.,  \: h_{\theta}(x^{(i)})\in(0,1) \\ \nonumber
&amp;amp;=&amp;amp; - y^{(i)}\log{h_{\theta}(x^{(i)})} - (1-y^{(i)})\log(1-h_{\theta}(x^{(i)}))
\end{eqnarray}$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hence our cost function becomes:
$$J(\theta) = -\frac{1}{m}[\sum_{i=1}^{m} ( y^{(i)}\log{h_{\theta}(x^{(i)})} + (1-y^{(i)})\log({1-h_{\theta}(x^{(i)}))})]$$&lt;/p&gt;
&lt;p&gt;We don't sum over the bias terms hence starting at 1 for the summation. The above equation for the cost function will work if we have a single neuron in the output layer. Let's generalize this cost function so that we could use it for $k$ neurons in the output layer. 
$$J(\theta) = -\frac{1}{m}\sum_{i=1}^{m} \sum_{i=1}^{k}[ y^{(i)}_k\log{(h_{\theta}(x^{(i)})_k)} + (1-y^{(i)}_k)\log({1-(h_{\theta}(x^{(i)}))_k)}]$$&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 class=&quot;section-heading&quot;&gt;Regularization: $L^2$&lt;/h4&gt;

&lt;p&gt;Regularization helps us in handling the problem of overfitting. Most regularization approaches add a parameter norm penalty $\Omega(\theta)$ to the loss function $J$ to achieve better generalization of the model. In case of $L^2$ regularization, also known as weight decay, the penalty is equal to the sum of the square of all of the weight vectors.&lt;/p&gt;
$$\Omega(\theta) = \frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}((\theta_{ji}^l)^2)$$&lt;p&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\lambda&amp;gt;0$, is known as the regularization parameter&lt;/li&gt;
&lt;li&gt;$m$ is the size of our training set&lt;/li&gt;
&lt;li&gt;$L$ in the equation is the layer number&lt;/li&gt;
&lt;li&gt;$s$ is the neuron unit in the corresponding layer&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;&lt;p&gt;Regularizers work by trading increased bias for reduced variance. An effective regularizer is one that makes a proﬁtable trade, that is it reduces variance signiﬁcantly while not overly increasing the bias.&lt;/p&gt;
&lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;http://www.iro.umontreal.ca/~bengioy/dlbook/regularization.html&quot;&gt;Yoshua Bengio, Ian Goodfellow and Aaron Courville&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The Wikipedia has a descent article on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff&quot;&gt;bias-variance tradeoff&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[6]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# weight regularization parameter&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 

&lt;span class=&quot;c&quot;&gt;# ===============================================&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# cross entropy cost function with regularizarion&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ===============================================&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; costFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;truth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;#39;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]));&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# regularization term&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;regularization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)));&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regularization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# regularized cost&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[6]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;costFunction (generic function with 1 method)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 class=&quot;section-heading&quot;&gt;Backpropagation&lt;/h4&gt;

&lt;p&gt;Despite the name, &lt;a href=&quot;http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm&quot;&gt;backpropagation algorithm&lt;/a&gt; consist of two phases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Feedforward &lt;/li&gt;
&lt;li&gt;Backpropagation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The feedforward process is the same process we have been following in the previous posts. Using the feedforward process we calculate the weighted sum of inputs and apply the activation function to get an output as we move from layer to layer. In the end we come up with a output activation which could have some error as compared to the actual values. To have the output as close as possible to the actual values we use the backpropagation process to tune the weights.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/img/nn/ff_mnist.png&quot; alt=&quot;2-layer-neuralNetwork-feedforward&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Backpropagation is a way of computing gradients of expressions through recursive application of chain rule. We start from the output layer and go backwards calulating the gradient on the activations for each layer till the first hidden layer.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;From these gradients, which can be interpreted as an indication of how each layer’s output should change to reduce error, one can obtain the gradient on the parameters of each layer. The gradients on weights and biases can be immediately used as part of a stochastic gradient update (performing the update right after the gradients havebeen computed) or used with other gradient-based optimization methods.&lt;/p&gt;
&lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;http://www.iro.umontreal.ca/~bengioy/dlbook/regularization.html&quot;&gt;Yoshua Bengio, Ian Goodfellow and Aaron Courville&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/img/nn/bp_mnist.png&quot; alt=&quot;2-layer-neuralNetwork-backpropagation&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Since we are learning/tuning weights ($\theta$), we want to evaluate: $\dfrac{\partial J}{\partial \theta^{(l)}}$, with $l$ as the layer number. Using the chain rule, we can solve the above partial derivative as:
$$\dfrac{\partial J}{\partial \theta^{(l)}} = \underbrace{\dfrac{\partial J}{\partial z^{(l+1)}}}_{1} \underbrace{\dfrac{\partial z^{(l+1)}}{\partial \theta^{(l)}}}_{2}$$&lt;/p&gt;
&lt;p&gt;here, $z$ represents the input signal to a neuron which is the weighted sum of the outputs from the previous layer's neurons. Hence $(2)$ becomes:&lt;/p&gt;
$$\dfrac{\partial z^{(l+1)}}{\partial \theta^{(l)}} = a^{(l)}$$&lt;p&gt;where, $a$ is the value from applying activation function $g$ to $z$. Now let's look at $(1)$ and represent it as $\delta$. Since we start backpropagation from the last output layer, we can calculate the change in cost w.r.t weights as:
$$ \dfrac{\partial J}{\partial \theta^{(2)}} = \underbrace{\dfrac{\partial J}{\partial z^{(3)}}}_{\delta^{(3)}} \underbrace{\dfrac{\partial z^{(3)}}{\partial \theta^{(2)}}}_{a^{(2)}}$$&lt;/p&gt;
&lt;p&gt;where,
$$ \begin{eqnarray}
\delta^{(3)} &amp;amp;=&amp;amp; \dfrac{\partial J}{\partial z^{(3)}} \\
&amp;amp;=&amp;amp; -[\frac{yg'(z^{(3)})}{g(z^{(3)})} + \frac{(1-y)(-g'(z^{(3)}))}{1-g(z^{(3)})}] \\
&amp;amp;=&amp;amp; g(z^{(3)}) - y \\ \\
&amp;amp;&amp;amp;(\text{for sigmoid, $g'(z) = g(z)(1-g(z))$})
\end{eqnarray}$$&lt;/p&gt;
&lt;p&gt;In the squared error cost function, $\delta^{(3)}$ would have a factor of $g'(z^{(3)})$. This means that for a large difference between the truth and the hypothesis, the sigmoid gradient would become very low (sigmoid curve is flat at the top) and hence the learning of our model would be slow. Using the cross entropy cost function also saves us from that problem. In the current case the larger the error, the faster the neuron will learn.&lt;/p&gt;
&lt;p&gt;Similarly for the hidden layer we have:
$$ \dfrac{\partial J}{\partial \theta^{(1)}} = \underbrace{\dfrac{\partial J}{\partial z^{(2)}}}_{\delta^{(2)}} \underbrace{\dfrac{\partial z^{(2)}}{\partial \theta^{(1)}}}_{a^{(1)}}$$&lt;/p&gt;
&lt;p&gt;where,
$$ \begin{eqnarray}
\delta^{(2)} &amp;amp;=&amp;amp; \dfrac{\partial J}{\partial z^{(2)}} \\
&amp;amp;=&amp;amp; \dfrac{\partial J}{\partial z^{(3)}} \dfrac{\partial z^{(3)}}{\partial g(z^{(2)})} \dfrac{\partial g(z^{(2)})}{\partial z^{(2)}} \\
&amp;amp;=&amp;amp; \delta^{(3)} \theta^{(2)} g'(z^{(2)})
\end{eqnarray}$$&lt;/p&gt;
&lt;p&gt;The equations above may require special handling in order to perform matrix operations but basically we saw how the chain rule can be applied for the backpropagation algorithm.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We now have all the components for $\dfrac{\partial J}{\partial \theta^{l}}$, hence we can update the weights as:&lt;/p&gt;
$$\theta^{(l)} \leftarrow \theta^{(l)} - \frac{\alpha}{m} \dfrac{\partial J}{\partial \theta^{l}}$$&lt;p&gt;If the original cost function included a regularization term then we need to take it into account as well while taking the derivatives. Hence $\dfrac{\partial J}{\partial \theta^{l}}$ would also include the derivative of the regularization term, $\frac{\lambda}{m}\theta^{(l)}$.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[17]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# including one bias neuron in input layer&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# weights for the links connecting input layer to the hidden layer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputLayerSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hiddenLayerSize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#(785x25)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# including one bias neuron in hidden layer&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# weights for the links connecting hidden layer to the output layer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hiddenLayerSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputLayerSize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#(26x10)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# learning rate&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# number of iterations&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# cost per epoch&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;J&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ====================================================================&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Train the neural network using feedforward-backpropagation algorithm&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ====================================================================&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# Feedforward #&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# add one bias element (785x60000)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;#39;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#(25x60000)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# add one bias element (26x60000)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;#39;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#(10x60000)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;# cost &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;costFunction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    
    &lt;span class=&quot;c&quot;&gt;# Backpropagation process #&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;delta3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#(10x60000)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;delta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoidGradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#(25x10)*(10x60000).*(25x60000)&lt;/span&gt;
        
    &lt;span class=&quot;c&quot;&gt;#update weights&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;reg_theta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;reg_theta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_theta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
    
    &lt;span class=&quot;n&quot;&gt;reg_theta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;reg_theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reg_theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;If our implementation is correct, the cost of the predicted output after each iteration should drop. I'll cover another method (gradient check) in another post to validate our implementation. But for now let's check by plotting the cost per iteration.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[18]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# plot the cost per iteration&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Iterations&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Cost&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;on&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt&quot;&gt;&lt;/div&gt;


&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 class=&quot;section-heading&quot;&gt;Prediction and Accuracy&lt;/h2&gt;

&lt;p&gt;After training the model we'll check how well our model has learned all the weights to make a prediction. So we'll evaluate the performance on the train dataset first. We do it by following a way similar to the feedforward process. Consider that we now do not have randonly initialized weights but rather obtained after going through the backpropagation algorithm.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[10]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;##########################################################################&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# outputs the predicted label of X given the&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# trained weights of a neural network (Theta1, Theta2)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Similar to feedforward process.&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;##########################################################################&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dataSz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# size of the data&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataSz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# to save our prediction&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;#39;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataSz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# hidded layer output&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;h2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;#39;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# output layer&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# find the index with the max value in the array of size 10&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# subtract 1 from the index since we are using 1 to &lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# represent 0, 2 for 1 and so on (while calculating Y)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataSz&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[10]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;predict (generic function with 1 method)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[19]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# make prediction&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[12]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;###############################################&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# calculate the accuracy of the prediction&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;###############################################&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt; accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;truth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# calculate the % of predicted values&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# matching the actual values&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;truth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truth&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt output_prompt&quot;&gt;Out[12]:&lt;/div&gt;


&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;accuracy (generic function with 1 method)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[20]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# calculate accuracy&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;train accuracy: &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt&quot;&gt;&lt;/div&gt;
&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;train accuracy: 87.01333333333334
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;After calculating the accuracy on the train dataset, let's check the accuracy on the test dataset to be sure that we did not overfit the data. If there is too much difference then we might have to tune some parameters.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[14]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# ===============&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# load test data&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# ===============&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;XTest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yTest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[21]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# make prediction&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predTest&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Theta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Theta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;XTest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;In&amp;nbsp;[22]:&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-julia&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c&quot;&gt;# calculate accuracy&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;test accuracy: &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yTest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predTest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;


&lt;div class=&quot;output_area&quot;&gt;&lt;div class=&quot;prompt&quot;&gt;&lt;/div&gt;
&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;test accuracy: 86.18
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;That's all folks! Now our model can make the prediction on any new handwritten digit in a similar way as we made the prediction on the test dataset. There are different ways to improve the performance of the model or to make it run faster but I'll leave them for the coming posts.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;
&lt;div class=&quot;prompt input_prompt&quot;&gt;
&lt;/div&gt;
&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 class=&quot;section-heading&quot;&gt;References:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://arxiv.org/abs/1404.7828&quot;&gt;Deep Learning in Neural Networks: An Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cs.toronto.edu/~hinton/absps/naturebp.pdf&quot;&gt;Learning representations by back-propagating errors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://arxiv.org/abs/1206.5533&quot;&gt;Practical recommendations for gradient-based training of deep architectures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://class.coursera.org/ml-005&quot;&gt;Coursera Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://cs231n.github.io/optimization-2/&quot;&gt;CS 231n&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.iro.umontreal.ca/~bengioy/dlbook/mlp.html&quot;&gt;Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm&quot;&gt;UDFL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://work.caltech.edu/slides/slides10.pdf&quot;&gt;Learning from Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
</description>
        <pubDate>2015-06-12 12:00:00 +0000</pubDate>
        <link>http://lakshgupta.github.io/2015/06/12/NeuralNetwork/</link>
        <guid isPermaLink="true">http://lakshgupta.github.io/2015/06/12/NeuralNetwork/</guid>
        
        
      </item>
    
      <item>
        <title>Linear Regression</title>
        <description>&lt;p&gt;Alright, in the last &lt;a href=&quot;http://lakshgupta.github.io/2015/05/21/ArtificialNeuron/&quot;&gt;post&lt;/a&gt; we looked at the very basic building block of a neural network: a neuron. But what could possibly a single neuron be good for? Well, as I mentioned in my last post it can be used to learn very simple models. Let us try to solve a linear regression problem using a neuron.&lt;/p&gt;

&lt;blockquote&gt;
Linear regression is the simplest form of regression.  We model our system with a linear combination of features to produce one output.
&lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;http://briandolhansky.com/blog/artificial-neural-networks-linear-regression-part-1&quot;&gt;Brian Dolhansky&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 class=&quot;section-heading&quot;&gt;The Problem&lt;/h2&gt;

&lt;p&gt;I’ll use the problem used in the Andrew Ng’s machine learning course. The dataset is located &lt;a href=&quot;https://github.com/lakshgupta/lakshgupta.github.io/blob/master/data/ex1data1.txt&quot;&gt;here&lt;/a&gt;. We will try to predict the profit for the franchise based on the population of the city. We’ll use the previous data to prepare a model. So let us first understand the data.&lt;/p&gt;

&lt;center&gt;&lt;canvas id=&quot;inputData&quot; width=&quot;600&quot; height=&quot;400&quot;&gt;&lt;/canvas&gt;&lt;/center&gt;

&lt;p&gt;Looking at the data we can say that we don’t need a complex model and linear regression is good enough for our purpose.&lt;/p&gt;

&lt;h2 class=&quot;section-heading&quot;&gt;Training a model&lt;/h2&gt;

&lt;center&gt;&lt;canvas id=&quot;artificialneuron&quot; width=&quot;500&quot; height=&quot;150&quot;&gt;&lt;/canvas&gt;&lt;/center&gt;

&lt;p&gt;Our neuron will receive two values as an input. One of them is the actual value from the data and the other is a bias value. We usually include the bias value along with the input feature matrix x.&lt;/p&gt;

&lt;blockquote&gt;
b is the bias, a term that shifts the decision boundary away from the origin and does not depend on any input value.
&lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;http://en.wikipedia.org/wiki/Perceptron&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since we want to linearly fit the data, we’ll use the linear activation function. When our neuron will receive the inputs, we’ll calculate the weighted sum and consider that as our output from the neuron.&lt;/p&gt;
&lt;center&gt;$$f(x_i,w) = \phi(\sum\limits_{j=0}^n(w^j x_i^j)) = \sum\limits_{j=0}^n(w^j x_i^j) = w^Tx_i$$&lt;/center&gt;
&lt;p&gt;where &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; represents a row of a matrix&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; represetns an element of a matrix&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The other way to look at our setup is that we are trying to fit a line to the data represented as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_i = w^0x_i^0 + w^1b&lt;/script&gt;

&lt;p&gt;We then try to figure out how close our neuron output or prediction is from the actual answer, i.e. we’ll apply a &lt;a href=&quot;http://en.wikipedia.org/wiki/Loss_function&quot;&gt;loss function&lt;/a&gt;, also known as a cost function over our dataset. A commonly used one is the least square error:&lt;/p&gt;
&lt;center&gt;$$J(w) = \sum\limits_{i=0}^n(f(x_i,w) - y_i)^2$$&lt;/center&gt;
&lt;p&gt;The idea is to use this value to modify our randomly initialized weight matrix till the time we stop observing the decrease in the cost function value. The method we’ll use to modify the weight matrix is known as &lt;a href=&quot;http://en.wikipedia.org/wiki/Gradient_descent&quot;&gt;Gradient Descent&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;$$w = w - \frac{\alpha}{m}\Delta J(w)$$&lt;/center&gt;
&lt;p&gt;here &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; is the weight matrix&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; is the learning rate&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; is the size of our data acting as a normalizing factor&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\Delta J(w)&lt;/script&gt; is the gradient of the cost function with respect to each of the weight under consideration say weight for the connection between a neuron &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; and a neuron &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial w_{jk}} J(w) = \sum\limits_{i=0}^n 2\left(f(x_i, w)-y_i\right) \frac{\partial}{\partial w_{jk}} f(x_i, w) &lt;/script&gt;

&lt;p&gt;So let us train the model and see how it is behaving by plotting the results of the above equation in red using the weight matrix and the x-axis.&lt;/p&gt;
&lt;center&gt;
&lt;canvas id=&quot;fitData&quot; height=&quot;400px&quot; width=&quot;600&quot;&gt;
This text is displayed if your browser does not support HTML5 Canvas.
&lt;/canvas&gt;
&lt;/center&gt;

&lt;h2 class=&quot;section-heading&quot;&gt;Making a Prediction&lt;/h2&gt;
&lt;p&gt;To make a prediction we just need to use the modified weight matrix, obtained after the gradient descent step, along with the new input values and apply the same function we used above:&lt;/p&gt;
&lt;center&gt;$$f(x_i,w) = w^Tx_i$$&lt;/center&gt;

&lt;!-- ############# JAVASCRIPT ############--&gt;
&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;http://cdnjs.cloudflare.com/ajax/libs/numeric/1.2.6/numeric.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.4.4/p5.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/plot/scatter.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/utils/mathUtils.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/nn/canvas.js&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/nn/neuron.js&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/nn/neuralnet.js&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot;&gt; 
    
  //artificial neuron: linear model
  var _ancanvas = document.getElementById(&quot;artificialneuron&quot;);
  var _anctx = _ancanvas.getContext(&quot;2d&quot;);
  var neuronIn1 = new neuron(_anctx, 50, 40, neuronRadius,&quot;b&quot;);
  var neuronIn2 = new neuron(_anctx, 50, 110, neuronRadius, &quot;x_i^j&quot;);
  var	hiddenLayer= new neuron(_anctx, 200, 75, neuronRadius);
  _anctx.mathText(&quot;f(x_i, w)&quot;,200,120,{&quot;text-align&quot;: &quot;center&quot;});
  var neuronOut = new neuron(_anctx, 350, 75, neuronRadius,&quot;y&quot;);
  //input to hidden layer
  connectLayers([neuronIn1, neuronIn2], [hiddenLayer]);
  //hidden to output layer
  connectLayers([hiddenLayer], [neuronOut]);
  
  var iterations = 1000;//1500;
  var learningRate = 0.01;
  
  function setup(){
    loadTable(&quot;/data/ex1data1.txt&quot;,&quot;CSV&quot;,linReg);
  }
  
  function linReg(table){
    var rowCount = table.rows.length - 1;
    var X = Array.matrix(rowCount, 2, 0);
    var Y = Array.matrix(rowCount, 1, 0);
    J_history = Array.matrix(iterations,1, 0);
    var m = X.length;
    //var theta = numeric.random([2,1]);
    var theta = Array.matrix(2,1,0);
    var xMax = table.getNum(0,0);
    var xMin = table.getNum(0,0);
    var yMax = table.getNum(0,1);
    var yMin = table.getNum(0,1);
    //load X and Y from table
    for(var i=0; i&lt;rowCount; i++){
      X[i][0] = table.getNum(i,0);
      X[i][1] = 1;
      Y[i][0] = table.getNum(i,1);
      //find min and max
      if(xMax &lt; X[i][0]){
        xMax = X[i][0];
      }
      if(xMin &gt; X[i][0]){
        xMin = X[i][0];
      }
      if(yMax &lt; Y[i][0]){
        yMax = Y[i][0];
      }
      if(yMin &gt; Y[i][0]){
        yMin = Y[i][0];
      }
    }
    //plot input data
    var chartInfo= { y:{min:yMin, max:yMax, steps:5,label:&quot;Profit in $10,000s&quot;},
                      x:{min:xMin, max:xMax, steps:5,label:&quot;Population of City in 10,000s&quot;}
    };
    var inputPlot = new scatter(&quot;inputData&quot;,chartInfo, X, Y);
        
    //compute initial cost
    console.log(&quot;Initial cost: &quot;+ computeCost(X,Y, theta));
    console.log(&quot;Initial theta: &quot;+theta);
    //run gradient descent
    for(var i=0;i&lt;iterations;i++){
	    var tempTheta = theta;
	    //console.log(&quot;gradient descent theta: &quot; +theta);
	    //for each weight
	    var subCorrection1 = numeric.sub(numeric.dot(X, tempTheta), Y);
	    //console.log(&quot;subCorrection1: &quot;+subCorrection1);
	    
	    for (var j=0; j &lt; theta.length; j++)
	    {
	        //console.log(&quot;weight: &quot;+j);
	        //for each input row
	        var subCorrection2 = subCorrection1.slice(0);
	        for(var k=0;k&lt;m;k++)
	        {
	          //console.log(&quot;before subCorrection2[k]: &quot;+ subCorrection2[k]);
		        subCorrection2[k] = subCorrection2[k]*X[k][j];
		        //console.log(&quot;x val: &quot;+ X[k][j]);
		        //console.log(&quot;after subCorrection2[k]: &quot;+ subCorrection2[k]);
	        }
	        //console.log(subCorrection2);
	        correction = (learningRate/m) * numeric.sum(subCorrection2);
	        subCorrection2 = new Array();// = [];
	        //console.log(&quot;after haha subcorrection2: &quot;+subCorrection2);
	        //console.log(&quot;after haha subcorrection1: &quot;+subCorrection1);
		      //console.log(&quot;correction: &quot;+correction);
		      theta[j] = theta[j] - correction;
      }
      //Save the cost J in every iteration    
      J_history[i] = computeCost(X, y, theta);
    }
    console.log(&quot;Cost history: &quot;+J_history);
    console.log(&quot;Final theta: &quot;+ theta);
    //plot the linear fit
    var fitChartInfo= { y:{min:yMin, max:yMax, steps:5,label:&quot;Profit in $10,000s&quot;},
                      x:{min:xMin, max:xMax, steps:5,label:&quot;Population of City in 10,000s&quot;}
    };
    var fitPlot = new scatter(&quot;fitData&quot;,fitChartInfo, X, Y);
    //console.log(theta);
    fitPlot.plotLine(theta);
    
  }
  
  
  //loss function
  function computeCost(x,y, theta){
    var m = 1;
    if(Array.isArray(x)){
      m = x.length;
    } 
    return numeric.sum(numeric.pow(numeric.sub(numeric.dot(x, theta), y),2));///(2*m);
  };
&lt;/script&gt;

</description>
        <pubDate>2015-05-27 12:00:00 +0000</pubDate>
        <link>http://lakshgupta.github.io/2015/05/27/LinearRegression/</link>
        <guid isPermaLink="true">http://lakshgupta.github.io/2015/05/27/LinearRegression/</guid>
        
        
      </item>
    
      <item>
        <title>Artificial Neuron</title>
        <description>&lt;p&gt;Billions of neuron work together in a highly parallel manner to form the most sophisticated computing device known as the human brain. A single neuron:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;receives the electrical signals from the axons of other neurons through dendrites. Signals can come from different organs such as eyes and ears.&lt;/li&gt;
  &lt;li&gt;modulates the signals in various amounts at the synapses between the dendrite and axons.&lt;/li&gt;
  &lt;li&gt;fires an output signal only when the total strength of the input signals exceed a certain threshold. This signal is sent further to other neurons.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;
&lt;center&gt;
&lt;img src=&quot;/img/nn/bioneuron.jpg&quot; alt=&quot;Biological Neuron&quot; /&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;A Biological Neuron&lt;/span&gt;
&lt;/center&gt;

&lt;p&gt;More information about a biological neuron can be found on &lt;a href=&quot;http://en.wikipedia.org/wiki/Neuron&quot;&gt;Wikipedia&lt;/a&gt;.&lt;/p&gt;

&lt;h2 class=&quot;section-heading&quot;&gt;Artificial Neuron&lt;/h2&gt;
&lt;p&gt;An artificial neuron is a mathematical model of a biological neuron. The steps mentined for a biological neuron can be mapped to an artificial neuron as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;an artificial neuron receives the input as numerical values rather than the electrical signals. Input can come from different sources such as an image or a text.&lt;/li&gt;
  &lt;li&gt;it then multiplies each of the input value by a value called the weight.&lt;/li&gt;
  &lt;li&gt;weighted sum is calculated then to represent the total strength of the input signal, and an activation function is applied on the sum to get the output. This output can be sent further to other artificial neurons.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
The artificial neuron receives one or more inputs (representing dendrites) and sums them to produce an output (representing a neuron's axon). Usually the sums of each node are weighted, and the sum is passed through a non-linear function known as an activation function or transfer function. The transfer functions usually have a sigmoid shape, but they may also take the form of other non-linear functions, piecewise linear functions, or step functions. They are also often monotonically increasing, continuous, differentiable and bounded.
&lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;http://en.wikipedia.org/wiki/Artificial_neuron&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Considering only a single input vector x:&lt;/p&gt;
&lt;center&gt;&lt;canvas id=&quot;artificialneuron&quot; width=&quot;500&quot; heigth=&quot;400&quot;&gt;&lt;/canvas&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;f(x,w) = \phi(\sum\limits_{i=0}^n(w_i x_i)) = \phi(w^Tx)&lt;/script&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; is our activation function.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; are the elements of the input vector x.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt; are the elements of the weight vector w. &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; is the output.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Notice that in terms of “learning” in almost all of the machine learning algorithms, we learn the weight parameters &lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt;. &lt;/p&gt;

&lt;h2 class=&quot;section-heading&quot;&gt;Activation Function&lt;/h2&gt;
&lt;p&gt;An artificial neuron using a step activation function is known as a Perceptron. Perceptron can act as a binary classifier based on if the value of the activation function is above or below a threashold. But step activation function may not be a good choice every time.&lt;/p&gt;

&lt;blockquote&gt;
  In fact, a small change in the weights or bias of any single perceptron in the network can sometimes cause the output of that perceptron to completely flip, say from 0 to 1. That flip may then cause the behaviour of the rest of the network to completely change in some very complicated way. So while your &quot;9&quot; might now be classified correctly, the behaviour of the network on all the other images is likely to have completely changed in some hard-to-control way. That makes it difficult to see how to gradually modify the weights and biases so that the network gets closer to the desired behaviour.
  &lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;http://neuralnetworksanddeeplearning.com/chap1.html&quot;&gt;Michael Nielsen&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There are other activation functions which seem to work generally better in most of the cases, such as tanh or maxout functions.&lt;/p&gt;

&lt;blockquote&gt;
  &quot;What neuron type should I use?&quot; Use the ReLU non-linearity, be careful with your learning rates and possibly monitor the fraction of &quot;dead&quot; units in a network. If this concerns you, give Leaky ReLU or Maxout a try. Never use sigmoid. Try tanh, but expect it to work worse than ReLU/Maxout.
  &lt;p align=&quot;right&quot;&gt;- &lt;a href=&quot;http://cs231n.github.io/neural-networks-1/&quot;&gt;Andrej Karpathy&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;center&gt;
 &lt;canvas id=&quot;step&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;&lt;/canvas&gt;
 &lt;canvas id=&quot;sigmoid&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;&lt;/canvas&gt;
 &lt;canvas id=&quot;tanh&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;&lt;/canvas&gt;
&lt;/center&gt;

&lt;p&gt;This ends the brief overview of a neuron. In the coming posts I’ll try to cover some of the things we can do with a neuron. Till then, enjoy!&lt;/p&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/nn/canvas.js&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/nn/neuron.js&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/nn/neuralnet.js&quot;&gt;&lt;/script&gt;

&lt;script language=&quot;javascript&quot; type=&quot;text/javascript&quot; src=&quot;/js/plot/eqgraph.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;script&gt;
//artificial neuron
var _ancanvas = document.getElementById(&quot;artificialneuron&quot;);
var _anctx = _ancanvas.getContext(&quot;2d&quot;);
var neuronIn1 = new neuron(_anctx, 50, 40, neuronRadius,&quot;x_0&quot;);
var neuronIn2 = new neuron(_anctx, 50, 110, neuronRadius, &quot;x_n&quot;);
var	hiddenLayer= new neuron(_anctx, 200, 75, neuronRadius);
_anctx.mathText(&quot;f(x,w)&quot;,200,120,{&quot;text-align&quot;: &quot;center&quot;});
var neuronOut = new neuron(_anctx, 350, 75, neuronRadius,&quot;y&quot;);
//input to hidden layer
connectLayers([neuronIn1, neuronIn2], [hiddenLayer]);
//hidden to output layer
connectLayers([hiddenLayer], [neuronOut]);

//plot step
function step(z){ 
        if(z &lt; 2){
          return 0;
        }else{
          return 1;
        }
      }
var stepGraph = new EqGraph({canvasId: 'step', minX: -4, minY: -2, maxX: 4, maxY: 2, unitsPerTick: 1 });
stepGraph.drawEquation(step , 'blue', 2);
var stepCanv = document.getElementById('step');
var stepcontext = stepCanv.getContext('2d');
stepcontext.font = 'italic 14pt Calibri';
stepcontext.fillStyle = '#777';
stepcontext.fillText('step', 10, stepCanv.height-5);

//plot sigmoid
function sigmoid(z){ return  1.0/(1.0+Math.exp(-z));}
var sigmoidGraph = new EqGraph({canvasId: 'sigmoid', minX: -6, minY: -2, maxX: 6, maxY: 2, unitsPerTick: 1 });
sigmoidGraph.drawEquation(sigmoid , 'blue', 2);
var sigmoidCanv = document.getElementById('sigmoid');
var sigmoidcontext = sigmoidCanv.getContext('2d');
sigmoidcontext.font = 'italic 14pt Calibri';
sigmoidcontext.fillStyle = '#777';
sigmoidcontext.fillText('sigmoid', 10, sigmoidCanv.height-5);

//plot tanh
function tanh(z){ return (Math.exp(z)-Math.exp(-z))/(Math.exp(z)+Math.exp(-z));}
var tanhGraph = new EqGraph({canvasId: 'tanh', minX: -6, minY: -2, maxX: 6, maxY: 2, unitsPerTick: 1 });
tanhGraph.drawEquation(tanh , 'blue', 2);
var tanhCanv = document.getElementById('tanh');
var tanhcontext = tanhCanv.getContext('2d');
tanhcontext.font = 'italic 14pt Calibri';
tanhcontext.fillStyle = '#777';
tanhcontext.fillText('tanh', 10, tanhCanv.height-5);

&lt;/script&gt;

</description>
        <pubDate>2015-05-21 12:00:00 +0000</pubDate>
        <link>http://lakshgupta.github.io/2015/05/21/ArtificialNeuron/</link>
        <guid isPermaLink="true">http://lakshgupta.github.io/2015/05/21/ArtificialNeuron/</guid>
        
        
      </item>
    
  </channel>
</rss>
