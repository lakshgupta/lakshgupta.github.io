{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/JuliaLang/julia/issues/14099\n",
    "const spaces = filter(isspace, Char(0):Char(0x10FFFF));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0.0,0.0,1.0],[0.0,0.0,1.0]),([0.0,1.0,0.0],[1.0,0.0,0.0]),([0.0,0.0,1.0],[0.0,1.0,0.0]),([0.0,0.0,1.0],[0.0,0.0,1.0]),([1.0,0.0,0.0],[0.0,0.0,1.0]),([0.0,1.0,0.0],[1.0,0.0,0.0])]\n"
     ]
    }
   ],
   "source": [
    "file = open(\"data/pos/05-train-input.txt\");\n",
    "vocabSet = Set();\n",
    "tagSet = Set();\n",
    "# read line\n",
    "for ln in eachline(file)\n",
    "    word_tag = split(ln, spaces);\n",
    "    # remove \"\"\n",
    "    word_tag = word_tag[word_tag .!= \"\"]\n",
    "    # separate word from tag\n",
    "    for token in word_tag\n",
    "        tokenSplit = split(token, \"_\");\n",
    "        push!(vocabSet, tokenSplit[1]);\n",
    "        push!(tagSet, tokenSplit[2]);\n",
    "    end\n",
    "end\n",
    "close(file);\n",
    "#println(vocabSet)\n",
    "#println(tagSet)\n",
    "# vocabulary dict\n",
    "wordDict = Dict{AbstractString, Vector{Float64}}();\n",
    "vocabSize = length(vocabSet);\n",
    "for (index, value) in enumerate(vocabSet)\n",
    "    val = zeros(vocabSize);\n",
    "    val[index] = 1;\n",
    "    wordDict[value] = val;\n",
    "end\n",
    "#println(wordDict);\n",
    "# tag dict\n",
    "tagDict = Dict{AbstractString, Vector{Float64}}();\n",
    "tagSize = length(tagSet);\n",
    "for (index, value) in enumerate(tagSet)\n",
    "    val = zeros(tagSize);\n",
    "    val[index] = 1;\n",
    "    tagDict[value] = val;\n",
    "end\n",
    "#println(tagDict);\n",
    "# prepare data array\n",
    "data = Tuple{Vector{Float64}, Vector{Float64}}[];\n",
    "file = open(\"data/pos/05-train-input.txt\");\n",
    "# read line\n",
    "for ln in eachline(file)\n",
    "    word_tag = split(ln, spaces);\n",
    "    # remove \"\"\n",
    "    word_tag = word_tag[word_tag .!= \"\"]\n",
    "    # separate word from tag\n",
    "    for token in word_tag\n",
    "        tokenSplit = split(token, \"_\");\n",
    "        push!(data, (wordDict[tokenSplit[1]], tagDict[tokenSplit[2]]));\n",
    "    end\n",
    "end\n",
    "close(file);\n",
    "#println(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function tanhGradient(x)\n",
    "    return (1 - x^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function forwardRNN(activationFn::Function, Winx, Winh, Bin, Wouth, Bout, x)\n",
    "    h = [] # hidden layers (at time t)\n",
    "    p = [] # output probability distribution (at time t)\n",
    "    y = [] # output values (at time t)\n",
    "    cost = 0;\n",
    "    # for each time t in x\n",
    "    for time in 1:len(x)\n",
    "        if time > 1\n",
    "            h[time] = activationFn(Winx * x[time] + Winh * h[time - 1]+ Bin);\n",
    "        else\n",
    "            h[time] = activationFn(Winx * x[time] + Bin);\n",
    "        end\n",
    "        # output layer\n",
    "        score = Wouth * h[time] +Bout;\n",
    "        p[time] = exp() ./ sum(exp(score), 2);\n",
    "        #cost = cost + (-log())\n",
    "        y[time] = find_max(p[time]);\n",
    "    end\n",
    "    return h, p, y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function backwardRNN(activationFnGrad::Function, Winx, Winh, Bin, Wouth, Bout, x, h, p, yCap)\n",
    "    gradWinx = []\n",
    "    gradWinh = []\n",
    "    gradBin = []\n",
    "    gradWouth = []\n",
    "    gradBout = []\n",
    "    \n",
    "    deltaIn = zeros(len(Bin)); # error from the following time step\n",
    "    for time in 1:-1:len(x)\n",
    "        pCap = createOneHot(yCap);\n",
    "        # output layer error\n",
    "        deltaOut = pCap - p[time];\n",
    "        # output gradient\n",
    "        gradWouth = gradWouth + (h[time] * deltaOut); \n",
    "        gradBout = gradBout + deltaOut;\n",
    "        # backpropagate\n",
    "        deltaInter = (deltaIn * Winh) + (deltaOut * Wouth);\n",
    "        deltaIn = deltaInter * activationFnGrad(h[time]);\n",
    "        # hidden layer gradient\n",
    "        gradWinx = gradWinx + (x[time] * deltaIn);\n",
    "        gradBin = gradBin + deltaIn;\n",
    "        if time != 1\n",
    "            gradWinh = gradWinh + (h[time - 1] * deltaIn);\n",
    "    end\n",
    "    return gradWinx, gradWinh, gradBin, gradWouth, gradBout\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function updateWeights()\n",
    "    Winx += lambda * gradWinx;\n",
    "    Winh += lambda * gradWinh;\n",
    "    Bin += lambda * gradBin;\n",
    "    Wouth += lambda * gradWouth;\n",
    "    Bout += lambda * gradBout;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [NLP Programming Tutorial](http://www.phontron.com/teaching.php)\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.2",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
