{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using ToyAD\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 3 # number of classes\n",
    "X = AD(zeros(N*K,D)) # data matrix (each row = single example)\n",
    "y = AD(zeros(N*K,1)) # class labels\n",
    "for j in range(1,K)\n",
    "    idx = range(1+N*(j-1), N); #index for X and Y\n",
    "    r = linspace(0.0,1,N); # radius\n",
    "    t = linspace((j-1)*4,(j)*4,N) + randn(N)*0.2 # theta\n",
    "    X.value[idx,:] = [r.*sin(t) r.*cos(t)]\n",
    "    y.value[idx,1] = j;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets visualize the data:\n",
    "scatter(X.value[:, 1], X.value[:, 2], s=40, c=y.value, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToyAD.AD(\"val\",[0.0 0.0 0.0],false,[0.0 0.0 0.0],ToyAD.ad_constD,ToyAD.AD[],1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize parameters randomly\n",
    "h = 100 # size of hidden layer\n",
    "W1 = AD(0.01 * randn(D,h))\n",
    "b1 = AD(zeros(1,h))\n",
    "W2 = AD(0.01 * randn(h,K))\n",
    "b2 = AD(zeros(1,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some hyperparameters\n",
    "step_size = 1e-0\n",
    "reg = 1e-3 # regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: DimensionMismatch(\"dimensions must match\")\nwhile loading In[8], in expression starting on line 5",
     "output_type": "error",
     "traceback": [
      "LoadError: DimensionMismatch(\"dimensions must match\")\nwhile loading In[8], in expression starting on line 5",
      "",
      " in promote_shape(::Tuple{Base.OneTo{Int64},Base.OneTo{Int64}}, ::Tuple{Base.OneTo{Int64},Base.OneTo{Int64}}) at .\\operators.jl:406",
      " in promote_shape(::Array{Float64,2}, ::Array{Float64,2}) at .\\operators.jl:397",
      " in _elementwise(::Base.#+, ::Type{Float64}, ::Array{Float64,2}, ::Array{Float64,2}) at .\\arraymath.jl:57",
      " in ad_addD(::Array{Float64,2}, ::Array{ToyAD.AD,1}) at C:\\Users\\lakshgupta\\.julia\\v0.5\\ToyAD\\src\\ADOperations.jl:18",
      " in backprop(::ToyAD.AD, ::Bool) at C:\\Users\\lakshgupta\\.julia\\v0.5\\ToyAD\\src\\Backprop.jl:9",
      " in macro expansion; at .\\In[8]:25 [inlined]",
      " in anonymous at .\\<missing>:?"
     ]
    }
   ],
   "source": [
    "# gradient descent loop\n",
    "num_examples = size(X.value,1)\n",
    "numIterations = 2\n",
    "J = zeros(numIterations,1);\n",
    "for i in 1:numIterations\n",
    "    # evaluate class scores, [N x K]\n",
    "    hidden1 = relu(X*W1 .+ b1) # note, ReLU activation\n",
    "    hidden2 = hidden1*W2 .+ b2\n",
    "    output = softmax(hidden2)\n",
    "    \n",
    "    #= compute the loss: average cross-entropy loss and regularization\n",
    "    corect_logprobs = zeros(num_examples)\n",
    "    for j in 1:num_examples\n",
    "        corect_logprobs[j] = -log(output.value[j,y[j]]);\n",
    "    end\n",
    "    data_loss = sum(corect_logprobs)/num_examples\n",
    "    reg_loss = 0.5*reg*sum(W1.value .^2) + 0.5*reg*sum(W2.value .^2)\n",
    "    J[i,:] = data_loss + reg_loss\n",
    "    if i==1 || i % 1000 == 0\n",
    "        println(\"iteration: \", i,\" loss: \", J[i,:])\n",
    "    end\n",
    "    =#\n",
    "    \n",
    "    # backpropate the gradient to the parameters\n",
    "    backprop(output, true)\n",
    "\n",
    "    # add regularization gradient contribution\n",
    "    #W2.derivative += reg * W2.value\n",
    "    #W1.derivative += reg * W1.value\n",
    "\n",
    "    # perform a parameter update\n",
    "    #W1.value += -step_size * W1.derivative\n",
    "    #W1.derivative = W1.derivative .* 0\n",
    "    #b1.value += -step_size * b1.derivative\n",
    "    #b1.derivative = b1.derivative .* 0\n",
    "    #W2.value += -step_size * W2.derivative\n",
    "    #W2.derivative = W2.derivative .* 0\n",
    "    #b2.value += -step_size * b2.derivative\n",
    "    #b2.derivative = b2.derivative .* 0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the cost per iteration\n",
    "plot(1:length(J), J)\n",
    "xlabel(\"Iterations\")\n",
    "ylabel(\"Cost\")\n",
    "grid(\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate training set accuracy\n",
    "hidden_layer = max(0, X*W1 .+ b1)\n",
    "scores = hidden_layer*W2 .+ b2\n",
    "predicted_class = zeros(size(scores,1))\n",
    "for i in 1:size(scores,1)\n",
    "    predicted_class[i] = indmax(scores[i,:])\n",
    "end\n",
    "#println(predicted_class)\n",
    "correct = 0;\n",
    "for i in 1:length(y)\n",
    "    if y[i] == predicted_class[i]\n",
    "        correct = correct + 1;\n",
    "    end\n",
    "end\n",
    "println(\"training accuracy: \", correct/length(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot the resulting classifier\n",
    "h = 0.02;\n",
    "x_min = minimum(X[:, 1]) - 1;\n",
    "x_max = maximum(X[:, 1]) + 1;\n",
    "y_min = minimum(X[:, 2]) - 1;\n",
    "y_max = maximum(X[:, 2]) + 1;\n",
    "numX = convert(Int, floor((x_max - x_min)/h));\n",
    "xx = zeros(numX);\n",
    "xx[1] = x_min;\n",
    "yy = zeros(numX);\n",
    "yy[1] = y_min;\n",
    "for i in 2:numX\n",
    "    xx[i] = xx[i-1] + h;\n",
    "    yy[i] = yy[i-1] + h;\n",
    "end\n",
    "grid_x = [i for i in xx, j in yy];\n",
    "grid_y = [j for i in xx, j in yy];\n",
    "xy = [grid_x[:] grid_y[:]];\n",
    "z0 = xy*W1 .+ b1\n",
    "z0[z0 .< 0] = 0 \n",
    "z = z0*W2 .+ b2\n",
    "zz = zeros(size(z,1));\n",
    "for i in 1:size(z,1)\n",
    "    zz[i] = indmax(z[i,:])\n",
    "end\n",
    "zz = reshape(zz, size(grid_x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contourf(grid_x, grid_y, zz, cmap=get_cmap(\"Spectral\"), alpha=0.8) \n",
    "scatter(X[:, 1], X[:, 2], c=y, s=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
