{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is a continuation of the [Neural Network](http://lakshgupta.github.io/2015/06/12/NeuralNetwork/) post where we learned about the basics of a neural network and applied it on the handwritten digit recognition problem. Here we'll cover the following topics which can help our neural network to perform better in terms of the accuracy of the model. \n",
    "- [Rectified linear unit (ReLU) function](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))\n",
    "- [Softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "- [Mini-batch gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "\n",
    "So let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using MNIST\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class=\"section-heading\">ReLU Activation Function : $$f(x) = max(0, x)$$</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sigmoid_relu](files/img/nn/sigmoid_relu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have already seen the sigmoid function instead of which we'll use ReLU activation function for the input and hidden layers in the current neural network architecture because it is faster and does not suffer from the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).  \n",
    "\n",
    ">- Biological plausibility: One-sided, compared to the antisymmetry of [tanh](https://en.wikipedia.org/wiki/Hyperbolic_function#Tanh).\n",
    ">- Sparse activation: For example, in a randomly initialized network, only about 50% of hidden units are activated (having a non-zero output).\n",
    ">- Efficient gradient propagation: No [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) or exploding effect.\n",
    ">- Efficient computation: Only comparison, addition and multiplication.\n",
    ">\n",
    ">For the first time in 2011, the use of the rectifier as a non-linearity has been shown to enable training deep supervised neural networks without requiring unsupervised pre-training. Rectified linear units, compared to [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) function or similar activation functions, allow for faster and effective training of deep neural architectures on large and complex datasets.\n",
    ">\n",
    ">Potential problems:\n",
    "Non-differentiable at zero: however it is differentiable at any point arbitrarily close to 0.\n",
    "<p>- <a href=\"https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\">Wikipedia</a></p>\n",
    "\n",
    "\n",
    ">\"What neuron type should I use?\" Use the ReLU non-linearity, be careful with your learning rates and possibly monitor the fraction of \"dead\" units in a network. If this concerns you, give Leaky ReLU or Maxout a try. Never use sigmoid. Try tanh, but expect it to work worse than ReLU/Maxout.\n",
    "<p>- <a href=\"http://cs231n.github.io/neural-networks-1/\">Andrej Karpathy</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relu (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReLU function\n",
    "function relu(z::Matrix{Float64})\n",
    "    return max(0.0, z);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sigmoid function\n",
    "function sigmoid(z::Matrix{Float64})\n",
    "    g = 1.0 ./ (1.0 + exp(-z));\n",
    "    return g;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class=\"section-heading\">Softmax Function : $$f_i(x) = \\frac{e^{x_i}}{\\sum_k e^{x_k}}$$</h4>\n",
    "\n",
    "Softmax function gives us normalized class probabilities. It takes the input, exponentiates it to generate unnormalized probabilities and then it uses a normalization factor to result in normalized probabilities. The output for each class lies between $0$ and $1$, and the sum of all the class probabilities is equal to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class=\"section-heading\">Forward Process</h4>\n",
    "\n",
    "I have re-structured the program to have replaceable components to make the experiment easy. There is a small change in the architecture of the neural network:\n",
    "- output layer will always be using the Softmax activation function\n",
    "- rest of all the layers we'll either use ReLU activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sigmoid](files/img/nn/softmax_nn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the introduction of the ReLU and Softmax function we can look at our forward step. \n",
    "At the first input layer:\n",
    "$$a^{(1)} = x$$\n",
    "\n",
    "At the hidden layer:\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "z^{(2)} = \\theta^{(1)}*a^{(1)} + bias^{(1)} \\\\[2ex]\n",
    "a^{(2)} = ReLU(z^{(2)})\n",
    "\\end{array} \n",
    "$$\n",
    "\n",
    "At the output layer:\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "z^{(3)} = \\theta^{(2)}*a^{(2)} + bias^{(2)} \\\\[2ex]\n",
    "\\hat y = softmax(z^{(3)})\n",
    "\\end{array} \n",
    "$$\n",
    "\n",
    "Each entry in $p$ vector defines our output normalized probability for that specific class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forwardNN (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function forwardNN(activationFn::Function, x::Matrix{Float64})\n",
    "    global network;\n",
    "    # collect input for each layer\n",
    "    # the last element will be the output from the neural network\n",
    "    activation = Matrix{Float64}[];\n",
    "    # initialize activation vector with the actual data\n",
    "    push!(activation, x);\n",
    "    for layer in 1:length(network)-1\n",
    "        push!(activation, activationFn((activation[layer]*network[layer][1]) .+ network[layer][2]))\n",
    "    end\n",
    "    # softmax on last layer\n",
    "    score = activation[length(network)]*network[length(network)][1] .+ network[length(network)][2]\n",
    "    exp_scores = exp(score);\n",
    "    yCap = exp_scores ./ sum(exp_scores, 2); \n",
    "\n",
    "    return activation, yCap;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class=\"section-heading\">Cost Function: $J$</h4>\n",
    "\n",
    "The [last time](http://lakshgupta.github.io/2015/06/12/NeuralNetwork/) we converted each output to an array of size $10$ with $1$ on the index representing the actual output and $0$ on the rest of the indices. Therefore we used a special case of the cross-entropy cost function where number of classes is equal to 2, assuming all of the output classes are independent of each other:\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{i=1}^{k}[ y^{(i)}_k\\log{(h_{\\theta}(x^{(i)})_k)} + (1-y^{(i)}_k)\\log({1-(h_{\\theta}(x^{(i)}))_k)}]$$\n",
    "\n",
    ">If we have multiple independent binary attributes by which to classify the data, we can use a network with multiple logistic outputs and cross-entropy error. For multinomial classification problems (1-of-n, where n > 2) we use a network with n outputs, one corresponding to each class, and target values of 1 for the correct class, and 0 otherwise. Since these targets are not independent of each other, however, it is no longer appropriate to use logistic output units. The corect generalization of the logistic sigmoid to the multinomial case is the softmax activation function.\n",
    "<p>- <a href=\"https://www.willamette.edu/~gorr/classes/cs449/classify.html\">Genevieve (Jenny) B. Orr</a></p>\n",
    "\n",
    "Since we are using softmax in the output layer, the probability for one class is divided by the sum of probabilities for all the classes. As a result, we will be using the generalized cross entropy cost function:\n",
    "\n",
    "\\begin{align}\n",
    "J(\\theta) = - \\left[ \\sum_{i=1}^{m} \\sum_{k=1}^{K}  1\\left\\{y^{(i)} = k\\right\\} \\log \\frac{\\exp(\\theta^{(k)\\top} x^{(i)})}{\\sum_{j=1}^K \\exp(\\theta^{(j)\\top} x^{(i)})}\\right]\n",
    "\\end{align}\n",
    "\n",
    ">In the probabilistic interpretation, we are therefore minimizing the negative log likelihood of the correct class, which can be interpreted as performing Maximum Likelihood Estimation (MLE). \n",
    "<p>- <a href=\"http://cs231n.github.io/linear-classify/\">Andrej Karpathy</a></p>\n",
    "\n",
    "More detailed information can be found [here](http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "costFunction (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function costFunction(truth::Vector{Float64}, probability::Matrix{Float64})\n",
    "    global network;\n",
    "    # average cross-entropy loss \n",
    "    m = size(truth,1)\n",
    "    \n",
    "    corect_logprobs = [-log(probability[j,convert(Int32, truth[j])]) for j in 1:m];\n",
    "    data_loss = sum(corect_logprobs)/m;\n",
    "    \n",
    "    #L2 regularization\n",
    "    reg_loss = 0;\n",
    "    for j in 1:length(network)\n",
    "        reg_loss = reg_loss + 0.5*lambda*sum(network[j][1].^2)/m;\n",
    "    end\n",
    "    \n",
    "    loss = data_loss + reg_loss;\n",
    "    return loss;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoidGradient (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient of the sigmoid function evaluated at a\n",
    "function sigmoidGradient(a::Matrix{Float64})\n",
    "  return a.*(1-a);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reluGradient (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient of the ReLU function evaluated at a\n",
    "function reluGradient(a::Matrix{Float64})\n",
    "    grad = ones(a);\n",
    "    grad[a.<=0] = 0;\n",
    "    return grad;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class=\"section-heading\">Backward process</h4>\n",
    "\n",
    "The algorithm to learn the parameters is still the same, backpropagation. We need to calculate the parameter gradients to update them using the chain rule. For simplicity consider the cost function for a single input,\n",
    "\n",
    "\\begin{align}\n",
    "J(\\theta) &= - \\left[ \\sum_{k=1}^{K} y_k* \\log (\\hat y_k) \\right]\n",
    "\\end{align}\n",
    "where,\n",
    "\n",
    "$$\\hat y_k = softmax(z^3_k) = \\frac{\\exp(z^3_k)}{\\sum_{j=1}^K \\exp(z^3_j) }$$\n",
    "and $y_k$ is either $0$ or $1$ as per the probability of the correct class. \n",
    "\n",
    "therefore, \n",
    "$$ \\frac{\\partial J}{\\partial \\hat y_k} = âˆ’ \\frac{y_k}{\\hat y_k} $$\n",
    "$$ \\frac{\\partial \\hat y_k}{\\partial z^{(3)}_i} = \\begin{cases} \n",
    "\\hat y_k(1-\\hat y_k),  & \\text{i = k} \\\\[2ex]\n",
    "-\\hat y_i \\hat y_k, & \\text{i $\\neq$ k} \\\\\n",
    "\\end{cases} \\\\\n",
    "$$\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial J}{\\partial z^{(3)}_i}\n",
    "&=&\\sum_{k = 1}^{K}\\frac{\\partial J}{\\partial \\hat y_k}\\frac{\\partial \\hat y_k}{\\partial z^{(3)}_i} \\\\ \\nonumber\n",
    "&=& \\underbrace{\\frac{\\partial J}{\\partial \\hat y_i}\\frac{\\partial \\hat y_i}{\\partial x_i}}_{i = k}\n",
    "+ \\underbrace{\\sum_{k \\neq i}\\frac{\\partial J(\\theta)}{\\partial \\hat y_k}\\frac{\\partial \\hat y_k}{\\partial x_i}}_{i \\neq k} \\\\ \\nonumber\n",
    "&=&-y_i(1 - \\hat y_i) + \\sum_{k \\neq i} y_k \\hat y_k \\\\ \\nonumber\n",
    "&=&-y_i + \\sum_{k} y_k \\hat y_k \\\\ \\nonumber\n",
    "&=& \\hat y_i - y_i \\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "The correct output element in the vector $y$ is always $1$ else $0$ since we are now dealing with the normalized class probabilities.\n",
    "\n",
    "For the softmax output layer:\n",
    "\n",
    "$$ \n",
    "\\begin{eqnarray}\n",
    "\\dfrac{\\partial J}{\\partial \\theta^{(2)}} \n",
    "&=& \\dfrac{\\partial J}{\\partial z^{(3)}} \\dfrac{\\partial z^{(3)}}{\\partial \\theta^{(2)}} \\\\\n",
    "&=& (\\hat y - y)* a^{(2)} \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\begin{eqnarray}\n",
    "\\dfrac{\\partial J}{\\partial bias^{(2)}} \n",
    "&=& \\dfrac{\\partial J}{\\partial z^{(3)}} \\dfrac{\\partial z^{(3)}}{\\partial bias^{(2)}} \\\\\n",
    "&=& (\\hat y - y)* 1 \n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "For the hidden layer with the ReLU activation function:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial J}{\\partial \\theta^{(1)}}\n",
    "&=&\\frac{\\partial J}{\\partial z^{(3)}}\\frac{\\partial z^{(3)}}{\\partial g(z^{(2)})}\\frac{\\partial g(z^{(2)})}{\\partial z^{(2)}}\\frac{\\partial z^{(2)}}{\\partial \\theta^{(1)}}\\\\ \\nonumber\n",
    "&=& (\\hat y - y)* \\theta^{(2)} * g'(z^{(2)})*a^{(1)} \\\\ \\nonumber\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial J}{\\partial bias^{(1)}}\n",
    "&=&\\frac{\\partial J}{\\partial z^{(3)}}\\frac{\\partial z^{(3)}}{\\partial g(z^{(2)})}\\frac{\\partial g(z^{(2)})}{\\partial z^{(2)}}\\frac{\\partial z^{(2)}}{\\partial bias^{(1)}}\\\\ \\nonumber\n",
    "&=& (\\hat y - y)* \\theta^{(2)} * g'(z^{(2)})*1 \\\\ \\nonumber\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Now we can update the weights as:\n",
    "\n",
    "$$\\theta^{(l)} \\leftarrow \\theta^{(l)} - \\alpha \\dfrac{\\partial J}{\\partial \\theta^{l}}$$\n",
    "\n",
    "All the above calculations is being performed by the backwordNN and the updateThetas method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backwardNN (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backwardNN(activationFnGrad::Function, a::Vector{Matrix{Float64}}, y::Vector{Float64}, dscores::Matrix{Float64})\n",
    "    global network;\n",
    "    m = size(y,1);\n",
    "    delta = Array(Matrix{Float64}, 1,length(network));\n",
    "    # start from the last layer to backpropagate the error\n",
    "    # compute the gradient on scores\n",
    "    for j in 1:size(dscores,1)\n",
    "        dscores[j,convert(Int32, y[j])] -= 1;\n",
    "    end\n",
    "    delta[length(network)] = dscores/m; # normalization factor\n",
    "    # backpropagate\n",
    "    for j in length(network)-1:-1:1\n",
    "        delta[j] = delta[j+1]*network[j+1][1]'.*activationFnGrad(a[j+1]);\n",
    "    end\n",
    "    return delta;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updateThetas (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function updateThetas(a::Vector{Matrix{Float64}}, delta::Matrix{Matrix{Float64}})\n",
    "    global network;\n",
    "    for j in 1:length(network)\n",
    "        # update theta\n",
    "        network[j][1] = network[j][1] - alpha*(a[j]'*delta[j] + lambda*network[j][1])\n",
    "        # update bias\n",
    "        network[j][2] =  network[j][2] - alpha*sum(delta[j],1);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(activationFn, data::Matrix{Float64})\n",
    "    activation, probs = forwardNN(activationFn, data);\n",
    "    predicted_class = [indmax(probs[i,:]) for i in 1:size(probs,1)]\n",
    "    return predicted_class;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function accuracy(truth, prediction)\n",
    "    correct = 0;\n",
    "    for i in 1:length(truth)\n",
    "        if truth[i] == prediction[i]\n",
    "            correct = correct + 1;\n",
    "        end\n",
    "    end\n",
    "    println(\"training accuracy: \", correct/length(truth)*100);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"section-heading\">Training a model</h2>\n",
    "\n",
    "Based on the new structure of the program, we'll build up our neural network and train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class=\"section-heading\">Load Data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "# ===================\n",
    "# load training data\n",
    "# ===================\n",
    "X,Y = traindata(); #X:(784x60000), y:(60000x1)\n",
    "X /= 255.0; # scale the input between 0 and 1\n",
    "X = X'; #X:(60000X784)\n",
    "Y = Y+1; # adding 1 to handle index, hence value 1 represent digit 0 now\n",
    "# number of instances\n",
    "println(size(Y,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class=\"section-heading\">Define Network</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputLayerSize = size(X,2);\n",
    "hiddenLayerSize = 100;\n",
    "outputLayerSize = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a network\n",
    "network = [];\n",
    "\n",
    "# add first layer to the network\n",
    "layer1 = Array(Matrix{Float64}, 1,2)\n",
    "#theta1\n",
    "layer1[1] = 0.01*randn(inputLayerSize, hiddenLayerSize); \n",
    "#bias1\n",
    "layer1[2] = zeros(1, hiddenLayerSize); \n",
    "push!(network,layer1);\n",
    "\n",
    "# add second layer to the network\n",
    "layer2 = Array(Matrix{Float64}, 1,2)\n",
    "#theta2\n",
    "layer2[1] = 0.01*randn(hiddenLayerSize, outputLayerSize); \n",
    "#bias2\n",
    "layer2[2] = zeros(1, outputLayerSize); \n",
    "push!(network,layer2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 class=\"section-heading\">Training: Mini-batch gradient descent</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The last time we used gradient descent to train our model. In this implementation we'll switch to Mini-Batch gradient descent algorithm which is not much different from regular gradient descent. It's just that instead of working on the whole dataset we'll work on a smaller dataset in each iteration. Because of this change our training algorithm will become computationally faster since large datasets are difficult to handle in memory which makes vectorization much less efficient. \n",
    "\n",
    ">In particular, suppose that our error function is particularly pernicious and has a bunch of little valleys. If we used the entire training set to compute each gradient, our model would get stuck in the first valley it fell into (since it would register a gradient of 0 at this point). If we use smaller mini-batches, on the other hand, we'll get more noise in our estimate of the gradient. This noise might be enough to push us out of some of the shallow valleys in the error function. \n",
    "><p>- <a href=\"https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-gradient-descent\">Quora</a></p>\n",
    "\n",
    "One thing to take care in the while training is that mini-batches need to be balanced for classes otherwise the estimation of the gradient using mini-batch gradient descent would be way off then the gradient calculated using the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 1e-0; # step size\n",
    "lambda = 1e-3; # regularization factor\n",
    "numItr = 1500;\n",
    "sampleCostAtEveryItr = 10;\n",
    "batchSize = convert(Int32,floor(size(X,1)/10));\n",
    "J = [];\n",
    "for itr in 1:numItr\n",
    "    # take next batch of random instances \n",
    "    minibatch = collect(rand(1:size(X,1), batchSize));\n",
    "    # feedforward\n",
    "    activations, probs = forwardNN(relu, X[minibatch,:]); \n",
    "    # cost\n",
    "    if itr%sampleCostAtEveryItr == 1\n",
    "        activationsX, probsX = forwardNN(relu, X); \n",
    "        push!(J, costFunction(Y, probsX));\n",
    "    end\n",
    "    # backpropagation\n",
    "    newThetas = backwardNN(reluGradient, activations, Y[minibatch], probs);\n",
    "    # update parameters\n",
    "    updateThetas(activations, newThetas);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is using ReLU activation function for the hidden layers but the program is modular enough to let us experiment with different activation functions, for example sigmoid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"section-heading\">Prediction and Accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 97.975\n"
     ]
    }
   ],
   "source": [
    "accuracy(Y, predict(relu, X));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is approximately 10% improvement over our previous implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <matplotlib.figure.Figure object at 0x0000000029DF85F8>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the cost per iteration\n",
    "sampleIdxJ = [1+sampleCostAtEveryItr*i for i in 0:length(J)-1]\n",
    "plot(sampleIdxJ, J)\n",
    "xlabel(\"Sampled Iterations\")\n",
    "ylabel(\"Cost\")\n",
    "grid(\"on\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spikes in the graph are due to the use of mini-batch gradient descent, which estimates the cost over the whole dataset hence sometimes moves away from the minima but in the end converges satisfactorily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 97.24000000000001\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "XTest,YTest = testdata();\n",
    "XTest /= 255.0;\n",
    "XTest = XTest';\n",
    "YTest = YTest+1;\n",
    "accuracy(YTest, predict(relu, XTest));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"section-heading\">References:</h2>\n",
    "\n",
    "- [Rectified linear unit (ReLU)](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))\n",
    "- [Learning representations by back-propagating errors](http://www.cs.toronto.edu/~hinton/absps/naturebp.pdf)\n",
    "- [Practical recommendations for gradient-based training of deep architectures](http://arxiv.org/abs/1206.5533)\n",
    "- [Efficient BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n",
    "- [Deep Learning](http://www.iro.umontreal.ca/~bengioy/dlbook/mlp.html)\n",
    "- [word2vec Parameter Learning Explained](http://arxiv.org/abs/1411.2738)\n",
    "- [binary cross entropy cost function with softmax?](https://www.reddit.com/r/cs231n/comments/45u13l/binary_cross_entropy_cost_function_with_softmax/)\n",
    "- [Combinatorial Information Theory: I. Philosophical Basis of Cross-Entropy and Entropy](http://arxiv.org/abs/cond-mat/0512017)\n",
    "- [word2vec gradients](https://courses.cs.ut.ee/MTAT.03.277/2015_fall/uploads/Main/word2vec.pdf)\n",
    "- [Softmax Regression](http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.2",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
